{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89c5079",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Proyecto MLOps: Modelo predictivo de ventas - Evaluaci贸n de para tienda Minorista\n",
    "\n",
    "Este proyecto forma parte de una pipeline de desarrollo y despliegue de modelos de machine learning en entornos productivos. El objetivo es construir un modelo robusto capaz de predecir el total de ventas mensuales de una tienda minorista, a partir de datos hist贸ricos diarios.\n",
    "\n",
    "El sistema se integrar谩 en una arquitectura MLOps donde los artefactos del modelo, la trazabilidad de experimentos, y las m茅tricas estar谩n disponibles para auditor铆a y versionado.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    " FASES DEL DESARROLLO DEL MODELO\n",
    "\n",
    "## 1. Ingesta y Preparaci贸n de Datos\n",
    "- Fuente: CSV / base de datos.\n",
    "- Procesos:\n",
    "    - Validaci贸n de esquema y tipos de datos.\n",
    "    - Imputaci贸n de valores faltantes.\n",
    "    - Codificaci贸n de variables categ贸ricas si aplica.\n",
    "    - Divisi贸n en conjuntos de entrenamiento, validaci贸n y test.\n",
    "\n",
    "## 2. An谩lisis Exploratorio de Datos (EDA)\n",
    "- An谩lisis visual y estad铆stico de distribuci贸n de ventas.\n",
    "- Evaluaci贸n de correlaciones entre variables predictoras y objetivo.\n",
    "- Agrupamientos temporales: comparativas entre d铆as h谩biles, festivos y fines de semana.\n",
    "- Identificaci贸n de outliers o patrones estacionales.\n",
    "\n",
    "## 3. Entrenamiento de Modelos Base\n",
    "- Modelos evaluados:\n",
    "    - `LinearRegression()`\n",
    "    - `DecisionTreeRegressor()`\n",
    "    - `RandomForestRegressor()`\n",
    "    - *(opcional: agregar Lasso, XGBoost, etc.)*\n",
    "- M茅tricas:\n",
    "    - Coeficiente de determinaci贸n: R虏\n",
    "    - Error cuadr谩tico medio (RMSE)\n",
    "    - Error absoluto medio (MAE)\n",
    "- T茅cnicas:\n",
    "    - B煤squeda de hiperpar谩metros (`GridSearchCV` / `RandomizedSearchCV`)\n",
    "    - Validaci贸n cruzada (`cross_val_score`)\n",
    "\n",
    "## 4. Evaluaci贸n y Visualizaci贸n\n",
    "- Generaci贸n de reportes con m茅tricas para cada modelo.\n",
    "- Gr谩ficos de comparaci贸n: ventas reales vs predichas.\n",
    "- An谩lisis de errores por categor铆a y por horizonte temporal.\n",
    "\n",
    "## 5. Empaquetado del Modelo\n",
    "- Serializaci贸n del mejor modelo (`joblib` o `pickle`).\n",
    "- Exportaci贸n de m茅tricas y visualizaciones.\n",
    "- Generaci贸n de archivo `requirements.txt` y documentaci贸n del entorno virtual.\n",
    "\n",
    "## 6. Preparaci贸n para Producci贸n (MLOps)\n",
    "- Scripts de inferencia reutilizables (`predict.py`)\n",
    "- Interfaz REST o CLI para consultas.\n",
    "- Documentaci贸n t茅cnica y funcional en README.md\n",
    "- (Opcional) Integraci贸n con `MLflow` para seguimiento de experimentos.\n",
    "- (Opcional) Despliegue en contenedor Docker / pipeline CI/CD.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    " OBJETIVO DEL MODELO\n",
    "Predecir el total de ventas para el mes siguiente en funci贸n de variables hist贸ricas,\n",
    "lo que permitir谩 a la tienda:\n",
    "- Optimizar su inventario.\n",
    "- Definir estrategias promocionales.\n",
    "- Asignar personal de forma eficiente.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Ь NOTAS ADICIONALES\n",
    "- Enfocado en reproducibilidad, modularidad y trazabilidad.\n",
    "- Compatible con flujos de trabajo de ciencia de datos y arquitectura MLOps.\n",
    "- C贸digo limpio, comentado y preparado para pruebas automatizadas.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ea7dd",
   "metadata": {},
   "source": [
    "## 1. Preparaci贸n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c21aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer铆as\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e1fa3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Datos/Ventas.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m ruta = \u001b[33m\"\u001b[39m\u001b[33m./Datos/Ventas.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Cargar el dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './Datos/Ventas.csv'"
     ]
    }
   ],
   "source": [
    "# Datos de la tienda minorista\n",
    "ruta = \"./Datos/Ventas.csv\"\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(ruta)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si hay valores faltantes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha' a tipo datetime\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "escala = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Eliminamos las columnas no deseadas y guardamos los nombres de las columnas que vamos a escalar\n",
    "columnas_para_escalar = df.drop([\"Ventas\", \"Fecha\"], axis=1).columns\n",
    "\n",
    "# Ajustamos el MinMaxScaler a las columnas restantes y transformamos los datos\n",
    "normado = escala.fit_transform(df[columnas_para_escalar])\n",
    "\n",
    "# Creamos un nuevo DataFrame con los datos normalizados y las columnas correctas\n",
    "df_normado = pd.DataFrame(data=normado, columns=columnas_para_escalar)\n",
    "\n",
    "# Si necesitas, puedes agregar las columnas no escaladas que has quitado previamente\n",
    "df_normado[\"Ventas\"] = df[\"Ventas\"]\n",
    "df_normado[\"Fecha\"] = df[\"Fecha\"]\n",
    "\n",
    "# Ahora df_normado tiene los datos normalizados y las columnas no normalizadas originales\n",
    "df_normado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobaci贸n del tipo de dato de Fecha\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aef07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar las variables dependientes e independientes\n",
    "X = df_normado.drop(['Ventas', 'Fecha'], axis=1)\n",
    "y = df['Ventas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58092f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_entrena, X_prueba, y_entrena, y_prueba = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20dd8b",
   "metadata": {},
   "source": [
    "## 2. An谩lisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94576a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad铆sticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci贸n de la distribuci贸n de ventas\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['Ventas'], bins=30, kde=True)\n",
    "plt.title('Distribuci贸n de Ventas')\n",
    "plt.xlabel('Ventas')\n",
    "plt.ylabel('Frecuencia');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relaci贸n entre ventas y d铆a de la semana con promedio de ventas\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df, x='D铆aDeLaSemana', y='Ventas', hue='D铆aDeLaSemana', palette='viridis')\n",
    "plt.title('Ventas promedio por D铆a de la Semana')\n",
    "plt.xlabel('D铆a de la Semana')\n",
    "plt.ylabel('Ventas Promedio');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot para comparar las ventas con y sin promociones.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Promociones', y='Ventas', data=df, hue='Promociones')\n",
    "plt.title('Efecto de las Promociones en las Ventas')\n",
    "\n",
    "# boxplot para comparar las ventas para los d铆as normales y festivos.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Festivo', y='Ventas', data=df,  hue='Festivo')\n",
    "plt.title('Efecto de los D铆as Festivos en las Ventas')\n",
    "\n",
    "# boxplot para ver la interacci贸n entre promociones y d铆as festivos en las ventas.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Promociones', y='Ventas',  hue='Promociones', data=df)\n",
    "plt.title('Interacci贸n entre Promociones y D铆as Festivos en las Ventas');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370695c",
   "metadata": {},
   "source": [
    "## 3. Selecci贸n de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b24e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# almacenar modelos\n",
    "modelos = [\n",
    "    (\"modelo lineal\", LinearRegression()),\n",
    "    (\"modelo arbol\", DecisionTreeRegressor(random_state=42)),\n",
    "    (\"modelo bosque\", RandomForestRegressor(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, modelo in modelos:\n",
    "    modelo.fit(X_entrena, y_entrena)\n",
    "    pred = modelo.predict(X_prueba)\n",
    "    r2 = r2_score(y_prueba, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_prueba, pred))  # corregido\n",
    "    print(f'{nombre}: R虏 = {r2:.3f}, RMSE = {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe3ec8",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento y evaluaci贸n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alojamos el modelo de Regresi贸n Lineal en una variable\n",
    "modelo_lineal = LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "modelo_lineal.fit(X_entrena, y_entrena)\n",
    "\n",
    "# Realizamos predicciones usando el conjunto de prueba\n",
    "predicciones_lineal = modelo_lineal.predict(X_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5562ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alojamos el modelo de Regresi贸n Lineal en una variable\n",
    "modelo_lineal = LinearRegression()\n",
    "modelo_lineal.fit(X_entrena, y_entrena)\n",
    "predicciones_lineal = modelo_lineal.predict(X_prueba)\n",
    "\n",
    "# C谩lculo de m茅tricas\n",
    "r2 = r2_score(y_prueba, predicciones_lineal)\n",
    "rmse = np.sqrt(mean_squared_error(y_prueba, predicciones_lineal))\n",
    "\n",
    "# Gr谩fico de dispersi贸n real vs predicho\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_prueba, predicciones_lineal, alpha=0.5)\n",
    "plt.plot([y_prueba.min(), y_prueba.max()], [y_prueba.min(), y_prueba.max()], linestyle='--')\n",
    "plt.xlabel('Ventas Reales')\n",
    "plt.ylabel('Ventas Predichas')\n",
    "plt.title(f'Modelo Lineal\\n$R^2$ = {r2:.3f}, RMSE = {rmse:.2f}')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'Real': y_prueba, 'Predicho': predicciones_lineal})\n",
    "df_test = df_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_test['Real'], label='Ventas Reales', alpha=0.7)\n",
    "plt.plot(df_test['Predicho'], label='Ventas Predichas', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('Comparaci贸n de Ventas Reales y Ventas Predichas a lo largo del tiempo');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ebe9b",
   "metadata": {},
   "source": [
    "## 5. Conclusi贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b090675",
   "metadata": {},
   "source": [
    "1. El primer gr谩fico, que muestra un diagrama de dispersi贸n de las Ventas Reales vs Ventas Predichas, sugiere que el modelo de regresi贸n lineal est谩 haciendo un buen trabajo al predecir las ventas. La l铆nea de tendencia indica una fuerte relaci贸n positiva entre los valores reales y predichos, lo que es un signo prometedor de que el modelo puede capturar la tendencia de las ventas con eficacia.\n",
    "2. El segundo gr谩fico compara las Ventas Reales y las Ventas Predichas a lo largo del tiempo y tambi茅n parece seguir un patr贸n similar, aunque hay algunos puntos en los que las predicciones y los valores reales difieren significativamente. Esto puede deberse a eventos no capturados por las variables en tu modelo o a variaciones naturales en las ventas que no son predecibles.\n",
    "\n",
    "Aqu铆 hay algunas recomendaciones para la tienda minorista:\n",
    "* Optimizaci贸n de Inventario: Utiliza las predicciones para gestionar mejor el inventario. Las fechas festivas pueden requerir un stock adicional para evitar la falta de productos.\n",
    "* Planificaci贸n de Personal: Ajusta los horarios del personal seg煤n d铆as festivos, y no necesariamente seg煤n dias de promociones. \n",
    "* Marketing Dirigido: Si identificas patrones de cu谩ndo las ventas son m谩s fuertes, puedes dirigir las campa帽as de marketing para esos periodos y potencialmente aumentar a煤n m谩s las ventas.\n",
    "* An谩lisis de Anomal铆as: Investiga aquellos puntos donde hay grandes desviaciones entre las ventas reales y las predichas para entender mejor los factores no capturados por el modelo.\n",
    "* Mejoras en el Modelo: Considera incluir m谩s variables en el modelo que puedan afectar las ventas, como datos econ贸micos generales, eventos locales, competencia, o incluso el clima.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
