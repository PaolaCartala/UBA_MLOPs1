{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89c5079",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Proyecto MLOps: Modelo predictivo de ventas - Evaluación de para tienda Minorista\n",
    "\n",
    "Este proyecto forma parte de una pipeline de desarrollo y despliegue de modelos de machine learning en entornos productivos. El objetivo es construir un modelo robusto capaz de predecir el total de ventas mensuales de una tienda minorista, a partir de datos históricos diarios.\n",
    "\n",
    "El sistema se integrará en una arquitectura MLOps donde los artefactos del modelo, la trazabilidad de experimentos, y las métricas estarán disponibles para auditoría y versionado.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "🔧 FASES DEL DESARROLLO DEL MODELO\n",
    "\n",
    "## 1. Ingesta y Preparación de Datos\n",
    "- Fuente: CSV / base de datos.\n",
    "- Procesos:\n",
    "    - Validación de esquema y tipos de datos.\n",
    "    - Imputación de valores faltantes.\n",
    "    - Codificación de variables categóricas si aplica.\n",
    "    - División en conjuntos de entrenamiento, validación y test.\n",
    "\n",
    "## 2. Análisis Exploratorio de Datos (EDA)\n",
    "- Análisis visual y estadístico de distribución de ventas.\n",
    "- Evaluación de correlaciones entre variables predictoras y objetivo.\n",
    "- Agrupamientos temporales: comparativas entre días hábiles, festivos y fines de semana.\n",
    "- Identificación de outliers o patrones estacionales.\n",
    "\n",
    "## 3. Entrenamiento de Modelos Base\n",
    "- Modelos evaluados:\n",
    "    - `LinearRegression()`\n",
    "    - `DecisionTreeRegressor()`\n",
    "    - `RandomForestRegressor()`\n",
    "    - *(opcional: agregar Lasso, XGBoost, etc.)*\n",
    "- Métricas:\n",
    "    - Coeficiente de determinación: R²\n",
    "    - Error cuadrático medio (RMSE)\n",
    "    - Error absoluto medio (MAE)\n",
    "- Técnicas:\n",
    "    - Búsqueda de hiperparámetros (`GridSearchCV` / `RandomizedSearchCV`)\n",
    "    - Validación cruzada (`cross_val_score`)\n",
    "\n",
    "## 4. Evaluación y Visualización\n",
    "- Generación de reportes con métricas para cada modelo.\n",
    "- Gráficos de comparación: ventas reales vs predichas.\n",
    "- Análisis de errores por categoría y por horizonte temporal.\n",
    "\n",
    "## 5. Empaquetado del Modelo\n",
    "- Serialización del mejor modelo (`joblib` o `pickle`).\n",
    "- Exportación de métricas y visualizaciones.\n",
    "- Generación de archivo `requirements.txt` y documentación del entorno virtual.\n",
    "\n",
    "## 6. Preparación para Producción (MLOps)\n",
    "- Scripts de inferencia reutilizables (`predict.py`)\n",
    "- Interfaz REST o CLI para consultas.\n",
    "- Documentación técnica y funcional en README.md\n",
    "- (Opcional) Integración con `MLflow` para seguimiento de experimentos.\n",
    "- (Opcional) Despliegue en contenedor Docker / pipeline CI/CD.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "🎯 OBJETIVO DEL MODELO\n",
    "Predecir el total de ventas para el mes siguiente en función de variables históricas,\n",
    "lo que permitirá a la tienda:\n",
    "- Optimizar su inventario.\n",
    "- Definir estrategias promocionales.\n",
    "- Asignar personal de forma eficiente.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "🧾 NOTAS ADICIONALES\n",
    "- Enfocado en reproducibilidad, modularidad y trazabilidad.\n",
    "- Compatible con flujos de trabajo de ciencia de datos y arquitectura MLOps.\n",
    "- Código limpio, comentado y preparado para pruebas automatizadas.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ea7dd",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c21aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e1fa3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Datos/Ventas.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m ruta = \u001b[33m\"\u001b[39m\u001b[33m./Datos/Ventas.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Cargar el dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './Datos/Ventas.csv'"
     ]
    }
   ],
   "source": [
    "# Datos de la tienda minorista\n",
    "ruta = \"./Datos/Ventas.csv\"\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(ruta)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si hay valores faltantes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha' a tipo datetime\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "escala = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Eliminamos las columnas no deseadas y guardamos los nombres de las columnas que vamos a escalar\n",
    "columnas_para_escalar = df.drop([\"Ventas\", \"Fecha\"], axis=1).columns\n",
    "\n",
    "# Ajustamos el MinMaxScaler a las columnas restantes y transformamos los datos\n",
    "normado = escala.fit_transform(df[columnas_para_escalar])\n",
    "\n",
    "# Creamos un nuevo DataFrame con los datos normalizados y las columnas correctas\n",
    "df_normado = pd.DataFrame(data=normado, columns=columnas_para_escalar)\n",
    "\n",
    "# Si necesitas, puedes agregar las columnas no escaladas que has quitado previamente\n",
    "df_normado[\"Ventas\"] = df[\"Ventas\"]\n",
    "df_normado[\"Fecha\"] = df[\"Fecha\"]\n",
    "\n",
    "# Ahora df_normado tiene los datos normalizados y las columnas no normalizadas originales\n",
    "df_normado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobación del tipo de dato de Fecha\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aef07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar las variables dependientes e independientes\n",
    "X = df_normado.drop(['Ventas', 'Fecha'], axis=1)\n",
    "y = df['Ventas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58092f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_entrena, X_prueba, y_entrena, y_prueba = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20dd8b",
   "metadata": {},
   "source": [
    "## 2. Análisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94576a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la distribución de ventas\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['Ventas'], bins=30, kde=True)\n",
    "plt.title('Distribución de Ventas')\n",
    "plt.xlabel('Ventas')\n",
    "plt.ylabel('Frecuencia');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relación entre ventas y día de la semana con promedio de ventas\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df, x='DíaDeLaSemana', y='Ventas', hue='DíaDeLaSemana', palette='viridis')\n",
    "plt.title('Ventas promedio por Día de la Semana')\n",
    "plt.xlabel('Día de la Semana')\n",
    "plt.ylabel('Ventas Promedio');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot para comparar las ventas con y sin promociones.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Promociones', y='Ventas', data=df, hue='Promociones')\n",
    "plt.title('Efecto de las Promociones en las Ventas')\n",
    "\n",
    "# boxplot para comparar las ventas para los días normales y festivos.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Festivo', y='Ventas', data=df,  hue='Festivo')\n",
    "plt.title('Efecto de los Días Festivos en las Ventas')\n",
    "\n",
    "# boxplot para ver la interacción entre promociones y días festivos en las ventas.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Promociones', y='Ventas',  hue='Promociones', data=df)\n",
    "plt.title('Interacción entre Promociones y Días Festivos en las Ventas');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370695c",
   "metadata": {},
   "source": [
    "## 3. Selección de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b24e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# almacenar modelos\n",
    "modelos = [\n",
    "    (\"modelo lineal\", LinearRegression()),\n",
    "    (\"modelo arbol\", DecisionTreeRegressor(random_state=42)),\n",
    "    (\"modelo bosque\", RandomForestRegressor(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, modelo in modelos:\n",
    "    modelo.fit(X_entrena, y_entrena)\n",
    "    pred = modelo.predict(X_prueba)\n",
    "    r2 = r2_score(y_prueba, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_prueba, pred))  # corregido\n",
    "    print(f'{nombre}: R² = {r2:.3f}, RMSE = {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe3ec8",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alojamos el modelo de Regresión Lineal en una variable\n",
    "modelo_lineal = LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "modelo_lineal.fit(X_entrena, y_entrena)\n",
    "\n",
    "# Realizamos predicciones usando el conjunto de prueba\n",
    "predicciones_lineal = modelo_lineal.predict(X_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5562ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alojamos el modelo de Regresión Lineal en una variable\n",
    "modelo_lineal = LinearRegression()\n",
    "modelo_lineal.fit(X_entrena, y_entrena)\n",
    "predicciones_lineal = modelo_lineal.predict(X_prueba)\n",
    "\n",
    "# Cálculo de métricas\n",
    "r2 = r2_score(y_prueba, predicciones_lineal)\n",
    "rmse = np.sqrt(mean_squared_error(y_prueba, predicciones_lineal))\n",
    "\n",
    "# Gráfico de dispersión real vs predicho\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_prueba, predicciones_lineal, alpha=0.5)\n",
    "plt.plot([y_prueba.min(), y_prueba.max()], [y_prueba.min(), y_prueba.max()], linestyle='--')\n",
    "plt.xlabel('Ventas Reales')\n",
    "plt.ylabel('Ventas Predichas')\n",
    "plt.title(f'Modelo Lineal\\n$R^2$ = {r2:.3f}, RMSE = {rmse:.2f}')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'Real': y_prueba, 'Predicho': predicciones_lineal})\n",
    "df_test = df_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_test['Real'], label='Ventas Reales', alpha=0.7)\n",
    "plt.plot(df_test['Predicho'], label='Ventas Predichas', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('Comparación de Ventas Reales y Ventas Predichas a lo largo del tiempo');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ebe9b",
   "metadata": {},
   "source": [
    "## 5. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b090675",
   "metadata": {},
   "source": [
    "1. El primer gráfico, que muestra un diagrama de dispersión de las Ventas Reales vs Ventas Predichas, sugiere que el modelo de regresión lineal está haciendo un buen trabajo al predecir las ventas. La línea de tendencia indica una fuerte relación positiva entre los valores reales y predichos, lo que es un signo prometedor de que el modelo puede capturar la tendencia de las ventas con eficacia.\n",
    "2. El segundo gráfico compara las Ventas Reales y las Ventas Predichas a lo largo del tiempo y también parece seguir un patrón similar, aunque hay algunos puntos en los que las predicciones y los valores reales difieren significativamente. Esto puede deberse a eventos no capturados por las variables en tu modelo o a variaciones naturales en las ventas que no son predecibles.\n",
    "\n",
    "Aquí hay algunas recomendaciones para la tienda minorista:\n",
    "* Optimización de Inventario: Utiliza las predicciones para gestionar mejor el inventario. Las fechas festivas pueden requerir un stock adicional para evitar la falta de productos.\n",
    "* Planificación de Personal: Ajusta los horarios del personal según días festivos, y no necesariamente según dias de promociones. \n",
    "* Marketing Dirigido: Si identificas patrones de cuándo las ventas son más fuertes, puedes dirigir las campañas de marketing para esos periodos y potencialmente aumentar aún más las ventas.\n",
    "* Análisis de Anomalías: Investiga aquellos puntos donde hay grandes desviaciones entre las ventas reales y las predichas para entender mejor los factores no capturados por el modelo.\n",
    "* Mejoras en el Modelo: Considera incluir más variables en el modelo que puedan afectar las ventas, como datos económicos generales, eventos locales, competencia, o incluso el clima.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
